# Privatemode API

Version: 1.30

On this page

Privatemode supports APIs that are mostly compatible with the [OpenAI API](https://platform.openai.com/docs/api-reference).
We like to highlight that we don't use any OpenAI services but only follow their interface definitions.
For sending prompts, simply use the [Privatemode proxy](/guides/proxy-configuration) as your endpoint. It'll take care of end-to-end encryption with our GenAI services for you.
For more information on the Privatemode proxy see the [architecture documentation](/architecture/client-side#privatemode-proxy) and the [configuration guide](/guides/proxy-configuration).

## Supported endpoints[â€‹](#supported-endpoints "Direct link to Supported endpoints")

* [**Chat completions**](/api/chat-completions)
* [**Completions**](/api/legacy-completions)
* [**Embeddings**](/api/embeddings)
* [**Models**](/api/models)
* [**Speech to text**](/api/speech-to-text)
* [**Translations**](/api/translations)

* [Supported endpoints](#supported-endpoints)
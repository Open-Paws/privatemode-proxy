# Multilingual E5 Large

Version: 1.30

On this page

Deprecated

This model is deprecated and will be removed on **December 14th, 2025**. Please migrate to an alternative model.

[Multilingual E5 Large Instruct](https://huggingface.co/intfloat/multilingual-e5-large-instruct) is an embedding model that was initialized from xlm-roberta-large and continually trained on a mixture of multilingual datasets.
It supports 100 languages from xlm-roberta.

## Model ID[​](#model-id "Direct link to Model ID")

`multilingual-e5-large`

## Source[​](#source "Direct link to Source")

[Hugging face](https://huggingface.co/intfloat/multilingual-e5-large-instruct)

## Modality[​](#modality "Direct link to Modality")

* Input: text
* Output: embedding vector

## Context limit[​](#context-limit "Direct link to Context limit")

* Embedding size: 1024; the model doesn't support reduced dimensions
* Maximum input size: 512 tokens

## Endpoints[​](#endpoints "Direct link to Endpoints")

* [`/v1/embeddings`](/api/embeddings)

* [Model ID](#model-id)
* [Source](#source)
* [Modality](#modality)
* [Context limit](#context-limit)
* [Endpoints](#endpoints)